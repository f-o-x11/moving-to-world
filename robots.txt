# Moving.to - Robots.txt for Maximum LLM Crawlability
# Updated: 2025-10-26

# Allow all major search engines and LLM crawlers
User-agent: *
Allow: /

# Explicitly allow LLM crawlers
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: GoogleOther
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: Applebot-Extended
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: YouBot
Allow: /

User-agent: Bytespider
Allow: /

User-agent: CCBot
Allow: /

User-agent: Diffbot
Allow: /

User-agent: FacebookBot
Allow: /

User-agent: ImagesiftBot
Allow: /

User-agent: Omgilibot
Allow: /

User-agent: Amazonbot
Allow: /

# Sitemap for efficient crawling
Sitemap: https://moving.to/sitemap.xml

# Crawl delay (none - allow maximum speed)
Crawl-delay: 0

# Priority pages for LLMs
Allow: /index.html
Allow: /locations.json
Allow: /cities-data.json
Allow: /**/index.html
